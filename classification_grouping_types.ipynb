{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorinhazan/FinalProject-DataScience/blob/main/classification_grouping_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import zipfile\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "dsdIkZocIcwQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aX3QUVycYhLZ",
        "outputId": "01b4cecc-d779-48e4-88ad-79132dd0da52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "p2HnWNG9IXAe",
        "outputId": "a192f8ba-1a37-48b8-d939-3d56bd941d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.81.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.81.0-py3-none-any.whl (717 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.5/717.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.1\n",
            "    Uninstalling openai-1.78.1:\n",
            "      Successfully uninstalled openai-1.78.1\n",
            "Successfully installed openai-1.81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf --quiet"
      ],
      "metadata": {
        "id": "CkYIhUcEIbN4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "# 1) Load the raw RTF\n",
        "with open(\"token_api_final_proj.rtf\", \"r\", encoding=\"utf-8\") as f:\n",
        "    rtf = f.read()\n",
        "\n",
        "# 2) Convert to plain text and strip whitespace\n",
        "key = rtf_to_text(rtf).strip()\n",
        "\n",
        "# 3) Export into os.environ\n",
        "os.environ[\"OPENAI_API_KEY\"] = key\n",
        "\n",
        "# 4) Verify\n",
        "print(\"✅ OPENAI_API_KEY loaded:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
      ],
      "metadata": {
        "id": "ij9SNWbz_WJA",
        "outputId": "c3bd34c8-8b4c-4b66-9b5e-012e21902cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OPENAI_API_KEY loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_ranking_path = \"merged_ranking.txt\"\n",
        "ranking_res_zip = \"/content/ranking_results.zip\"\n",
        "\n",
        "with zipfile.ZipFile(ranking_res_zip, 'r') as z, open(merged_ranking_path, 'w', encoding='utf-8') as out:\n",
        "    for info in z.infolist():\n",
        "        if info.filename.endswith('.txt'):\n",
        "            out.write(f\"===== {info.filename} =====\\n\")\n",
        "            with z.open(info) as f:\n",
        "                for raw in f:\n",
        "                    out.write(raw.decode('utf-8', errors='replace'))\n",
        "            out.write(\"\\n\\n\")\n",
        "\n",
        "print(f\"Done — all .txt merged into `{merged_ranking_path}`\")\n"
      ],
      "metadata": {
        "id": "5Vlc-kLBY2D2",
        "outputId": "094bd6dd-309f-4be5-f681-4c2661c6ff9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ranking_results.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c90d683d6498>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mranking_res_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/ranking_results.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranking_res_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_ranking_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ranking_results.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Update these paths\n",
        "obs_res_zip        = '/content/json_results.zip'\n",
        "extract_dir     = '/content/extracted_jsons/json_results'\n",
        "merged_json_path = 'merged_obs_extraction.json'\n",
        "\n",
        "# 2. Extract JSON files\n",
        "with zipfile.ZipFile(obs_res_zip, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "\n",
        "# 3. Merge into one dictionary, extending duplicates’ observables\n",
        "merged = {}\n",
        "for filename in os.listdir(extract_dir):\n",
        "    # only process .json files\n",
        "    if not filename.lower().endswith('.json'):\n",
        "        continue\n",
        "\n",
        "    full_path = os.path.join(extract_dir, filename)\n",
        "    with open(full_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for md_name, doc in data.items():\n",
        "        if md_name not in merged:\n",
        "            merged[md_name] = doc\n",
        "        else:\n",
        "            # extend observables list from both\n",
        "            merged[md_name][\"observables\"].extend(doc.get(\"observables\", []))\n",
        "            # you can merge other fields here if needed\n",
        "\n",
        "# 4. Save the merged JSON\n",
        "with open(merged_json_path, 'w') as f:\n",
        "    json.dump(merged, f, indent=2)"
      ],
      "metadata": {
        "id": "c1sBAQkEIf1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose your file was named “data.json”\n",
        "with open('merged_obs_extraction.json','r') as f:\n",
        "    merged_obs_extraction = json.load(f)"
      ],
      "metadata": {
        "id": "SUQRxhyCz4DE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract, lowercase, and dedupe classification values\n",
        "unique_classifications = {\n",
        "    obs['classification'].lower()\n",
        "    for doc in merged_obs_extraction.values()\n",
        "    for obs in doc.get('observables', [])\n",
        "    if 'classification' in obs\n",
        "}"
      ],
      "metadata": {
        "id": "lX-6rcQ3IgXz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_classifications.update(['api',\n",
        " 'api call',\n",
        " 'api function',\n",
        " 'api hook',\n",
        " 'archive file',\n",
        " 'attack effect',\n",
        " 'attack technique',\n",
        " 'authentication credential',\n",
        " 'authentication technique',\n",
        " 'boot record',\n",
        " 'c2 server',\n",
        " 'circuit breaker',\n",
        " 'code snippet',\n",
        " 'command',\n",
        " 'command line argument',\n",
        " 'command message',\n",
        " 'command parameters',\n",
        " 'command sequence',\n",
        " 'command value',\n",
        " 'command/utility',\n",
        " 'communication channel',\n",
        " 'communication interface',\n",
        " 'communication port',\n",
        " 'communication priority level',\n",
        " 'communication protocol',\n",
        " 'config/data file',\n",
        " 'configuration data',\n",
        " 'configuration file',\n",
        " 'configuration parameter',\n",
        " 'credential',\n",
        " 'credential list',\n",
        " 'data',\n",
        " 'data block',\n",
        " 'data manipulation',\n",
        " 'data transfer',\n",
        " 'database server',\n",
        " 'device',\n",
        " 'device configuration value',\n",
        " 'device state',\n",
        " 'device status parameter',\n",
        " 'distributed control system',\n",
        " 'dll file',\n",
        " 'document',\n",
        " 'domain name',\n",
        " 'driver file',\n",
        " 'dynamic-link library',\n",
        " 'electrical device',\n",
        " 'email message',\n",
        " 'error state',\n",
        " 'event log',\n",
        " 'executable command',\n",
        " 'executable file',\n",
        " 'exploit payload',\n",
        " 'exploit technique',\n",
        " 'facility',\n",
        " 'file',\n",
        " 'file type',\n",
        " 'file/script',\n",
        " 'firewall rule',\n",
        " 'firewall utility',\n",
        " 'firmware',\n",
        " 'frequency converter drive',\n",
        " 'function block memory location',\n",
        " 'hardware component',\n",
        " 'hex value',\n",
        " 'hmi device',\n",
        " 'host device',\n",
        " 'http request',\n",
        " 'ics address',\n",
        " 'ics application',\n",
        " 'ics command',\n",
        " 'ics command message',\n",
        " 'ics communication payload',\n",
        " 'ics communication protocol',\n",
        " 'ics configuration',\n",
        " 'ics configuration file',\n",
        " 'ics controller',\n",
        " 'ics data',\n",
        " 'ics data block recording',\n",
        " 'ics device',\n",
        " 'ics device parameter',\n",
        " 'ics field',\n",
        " 'ics function block',\n",
        " 'ics gateway',\n",
        " 'ics i/o snapshot',\n",
        " 'ics network communication',\n",
        " 'ics object',\n",
        " 'ics parameter',\n",
        " 'ics payload component',\n",
        " 'ics process data',\n",
        " 'ics project file',\n",
        " 'ics protocol',\n",
        " 'ics protocol field',\n",
        " 'ics protocol module',\n",
        " 'ics protocol parameter',\n",
        " 'ics protocol value',\n",
        " 'ics software module',\n",
        " 'ics systems',\n",
        " 'ics tag',\n",
        " 'identifier constant',\n",
        " 'impact condition',\n",
        " 'industrial communication protocol',\n",
        " 'industrial control device',\n",
        " 'industrial control module',\n",
        " 'industrial control system',\n",
        " 'industrial control system (ics) device',\n",
        " 'industrial control system device',\n",
        " 'industrial control system platform',\n",
        " 'industrial controller (cpu)',\n",
        " 'industrial network bus',\n",
        " 'integrity check routine',\n",
        " 'log files',\n",
        " 'malicious file',\n",
        " 'malicious ics function block',\n",
        " 'malicious logic',\n",
        " 'malicious software',\n",
        " 'malware',\n",
        " 'malware module',\n",
        " 'manufacturing facility',\n",
        " 'medical product',\n",
        " 'memory access pattern',\n",
        " 'memory access request',\n",
        " 'memory write attempt',\n",
        " 'module',\n",
        " 'monitor',\n",
        " 'network communication',\n",
        " 'network communication technique',\n",
        " 'network configuration',\n",
        " 'network connection',\n",
        " 'network data',\n",
        " 'network device',\n",
        " 'network entity',\n",
        " 'network identifier',\n",
        " 'network packet',\n",
        " 'network port',\n",
        " 'network protocol',\n",
        " 'network segment',\n",
        " 'network service',\n",
        " 'network service/port',\n",
        " 'network traffic',\n",
        " 'network traffic event',\n",
        " 'opc server',\n",
        " 'opc ua address space',\n",
        " 'opc ua server',\n",
        " 'operating system api',\n",
        " 'operational mode',\n",
        " 'os system call',\n",
        " 'packaging tool',\n",
        " 'payload file',\n",
        " 'plc',\n",
        " 'plc block',\n",
        " 'plc code',\n",
        " 'plc code component',\n",
        " 'plc cpu',\n",
        " 'plc data block',\n",
        " 'plc data block content (magic value)',\n",
        " 'plc device',\n",
        " 'plc function block',\n",
        " 'plc i/o image',\n",
        " 'plc operating system',\n",
        " 'plc organization block',\n",
        " 'plc program organization unit',\n",
        " 'plc runtime constraint',\n",
        " 'process',\n",
        " 'process name list',\n",
        " 'process termination',\n",
        " 'profibus communication module',\n",
        " 'program transfer operation',\n",
        " 'project file',\n",
        " 'protective relay',\n",
        " 'protocol',\n",
        " 'protocol field',\n",
        " 'protocol object data',\n",
        " 'protocol version',\n",
        " 'proxy server',\n",
        " 'python function call',\n",
        " 'registry key',\n",
        " 'remote access service',\n",
        " 'remote terminal unit',\n",
        " 'removable media',\n",
        " 'resource identifier',\n",
        " 'safety instrumented system',\n",
        " 'script',\n",
        " 'script engine/interpreter',\n",
        " 'script file',\n",
        " 'script framework',\n",
        " 'sensor reading',\n",
        " 'serial port',\n",
        " 'server',\n",
        " 'server information',\n",
        " 'service control',\n",
        " 'service/process',\n",
        " 'servo drive',\n",
        " 'shellcode',\n",
        " 'signature value',\n",
        " 'software/program',\n",
        " 'software/tool',\n",
        " 'software/tool (malware)',\n",
        " 'sql command',\n",
        " 'sql stored procedure',\n",
        " 'storage device',\n",
        " 'string',\n",
        " 'url',\n",
        " 'user account',\n",
        " 'variable state',\n",
        " 'vulnerability',\n",
        " 'vulnerability identifier',\n",
        " 'web script',\n",
        " 'windows registry key'])"
      ],
      "metadata": {
        "id": "y7LvUuSXzMyO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gross_classifications = set([\n",
        "\"System\",\n",
        "\"Module\",\n",
        "\"Hardware\",\n",
        "\"Device\",\n",
        "\"PLC\",\n",
        "\"POU\",\n",
        "\"Identifier\",\n",
        "\"Information\",\n",
        "\"Credential\",\n",
        "\"Data\",\n",
        "\"Command\",\n",
        "\"API\",\n",
        "\"Code\",\n",
        "\"Process\",\n",
        "\"Configuration\",\n",
        "\"Log\",\n",
        "\"File\",\n",
        "\"Payload\",\n",
        "\"Software\",\n",
        "\"Service\",\n",
        "\"Firmware\",\n",
        "\"Server\",\n",
        "\"Communication\",\n",
        "\"Protocol\",\n",
        "\"Protocol Field\",\n",
        "\"Connection Port\",\n",
        "\"Vulnerability\",\n",
        "\"Attack Technique\"])"
      ],
      "metadata": {
        "id": "1n3QQILtIjC0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a cybersecurity analyst expert. Your job is to group a list of observable “classification” labels under gross classifications from MITRE ATT&CK® Enterprise, or if not matched to any existing gross classification - create a new category that matches the observable group.\n",
        "\n",
        "---\n",
        "### Input\n",
        "   - A set of unique observable classifications:\n",
        "     {sorted(unique_classifications)}\n",
        "\n",
        "   - A set of gross classifications from MITRE ATT&CK® Enterprise:\n",
        "     {sorted(gross_classifications)}\n",
        "\n",
        "---\n",
        "### Task\n",
        "   - For each unique observable classifications, choose exactly one gross classification it best fits.\n",
        "   - If it does not clearly belong to any of the gross classification labels given, assign it to a new category of your own choosing, appending “– new” to that category name (e.g. “Data Management – new”).\n",
        "\n",
        "---\n",
        "### Output\n",
        "   - Return **only** a single JSON object.\n",
        "   - Do **not** include any words outside of that JSON—no explanations, no commentary.\n",
        "   - Do **not** add free text; only JSON format.\n",
        "   - Each key must be either one of the 28 gross classification label names or one of your “– new” categories.\n",
        "   - Each value must be an array of the unique observable classifications assigned to that key.\n",
        "\n",
        "---\n",
        "### Response format)\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"Code\": [\n",
        "    \"script file\"\n",
        "  ],\n",
        "  \"Command\": [\n",
        "    \"command string\"\n",
        "  ],\n",
        "  \"Identifier\": [\n",
        "    \"ip address\",\n",
        "    \"domain\"\n",
        "  ],\n",
        "  \"Data\": [\n",
        "    \"file format\",\n",
        "    \"file signature\"\n",
        "  ]\n",
        "  ...\n",
        "}}\n",
        "\n",
        "##\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yhVtjRmUIk2l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade openai\n"
      ],
      "metadata": {
        "id": "d3asVr8tImr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a8fb56-d48f-4aa2-d22d-e153671c6182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.81.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],  # or however you load it\n",
        ")\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"o3-mini-2025-01-31\",          # ← swap in your desired model\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful cybersecurity expert.\"},\n",
        "        {\"role\": \"user\",   \"content\": prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Extract the raw JSON string from the assistant’s reply\n",
        "raw = response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "7q4vsN_vIoTY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Strip out any leading/trailing whitespace\n",
        "clean = raw.strip()\n",
        "\n",
        "# 3. If it’s wrapped in triple‐backticks, remove them\n",
        "#    We look for the first `{` and the last `}`\n",
        "start = clean.find('{')\n",
        "end   = clean.rfind('}')\n",
        "if start != -1 and end != -1:\n",
        "    clean = clean[start:end+1]\n",
        "\n",
        "# 4. Now parse it\n",
        "groups_mapping = json.loads(clean)\n",
        "\n",
        "# 5. Write it out\n",
        "with open(\"groups_mapping.json\", \"w\") as f:\n",
        "    json.dump(groups_mapping, f, indent=2)\n",
        "\n",
        "print(\"✅ groups_mapping.json written\")"
      ],
      "metadata": {
        "id": "ccKVpONCP5ln",
        "outputId": "fa1e79c9-37c7-4176-8a0b-73911c7baff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ groups_mapping.json written\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Build reverse map: sub-classification (lowercase) → gross group name\n",
        "reverse_map = {}\n",
        "for gross_group, sub_list in groups_mapping.items():\n",
        "    for sub in sub_list:\n",
        "        reverse_map[sub.lower()] = gross_group\n"
      ],
      "metadata": {
        "id": "x56qNZhgVmDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_path = 'merged_obs_extraction.json'\n",
        "output_path = 'merged_obs_extraction_renamed.json'\n",
        "\n",
        "# Load the existing JSON\n",
        "with open(input_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Iterate over each file and its observables, renaming keys as requested\n",
        "for filename, content in data.items():\n",
        "    for obs in content.get('observables', []):\n",
        "        if 'observable_rank' in obs:\n",
        "            obs['artifact_details'] = obs.pop('observable_rank')\n",
        "        if 'classification' in obs:\n",
        "            obs['fine_classification'] = obs.pop('classification')\n",
        "\n",
        "# Save the updated JSON to a new file\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(f\"Renamed keys and saved the updated JSON to '{output_path}'\")"
      ],
      "metadata": {
        "id": "s0ZFcvPgXxRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_obs_extraction_renamed_path = \"/content/merged_obs_extraction_renamed.json\"\n",
        "with open(merged_obs_extraction_renamed_path, 'r') as f:\n",
        "    merged_obs_extraction_renamed = json.load(f)"
      ],
      "metadata": {
        "id": "gcsT2J7-T2Sc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4) Annotate each observable\n",
        "for doc_name, doc_data in merged_obs_extraction_renamed.items():\n",
        "    for obs in doc_data.get('observables', []):\n",
        "        # print(doc_data.get('observables', []))\n",
        "        cls = obs.get('fine_classification', '').lower()\n",
        "        # print(cls)\n",
        "        # look up the group, default to 'Unknown' if not found\n",
        "        obs['gross_classification'] = reverse_map.get(cls, 'Unknown')"
      ],
      "metadata": {
        "id": "Fh0pvZrTSqyj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observables_by_value_path = \"/content/observables_by_value.json\"\n",
        "with open(observables_by_value_path, 'r') as f:\n",
        "    observables_by_value = json.load(f)"
      ],
      "metadata": {
        "id": "5Qli6iViVoOL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Annotate each observable\n",
        "for doc_name, doc_data in observables_by_value.items():\n",
        "      cls = doc_data.get('fine_classification', '').lower()\n",
        "      doc_data['gross_classification'] = reverse_map.get(cls, 'Unknown')"
      ],
      "metadata": {
        "id": "U1DHxobYVlQ0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Save the enriched JSON\n",
        "out_path = '/content/merged_with_gross_classification-table.json'\n",
        "with open(out_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(observables_by_value, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Done—saved annotated file to {out_path}\")"
      ],
      "metadata": {
        "id": "MoJsRdnfTbcL",
        "outputId": "6c9cb10d-74d6-4bd7-df3e-d101449a1df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done—saved annotated file to /content/merged_with_gross_classification-table.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert csv table into json object in order to compare between observables"
      ],
      "metadata": {
        "id": "FHjcQxkLDOG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import json\n",
        "\n",
        "# 1) Load your CSV\n",
        "csv_path = \"/content/updated_Procedure_descriptions_observables_using_o3_mini_prompt_with_deprecation.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# 2) Rename your column\n",
        "df = df.rename(columns={\"classification\": \"fine_classification\"})\n",
        "\n",
        "# 3) Define exactly the columns you want (including the new ones)\n",
        "wanted = [\n",
        "    \"observable_value\",\n",
        "    \"artifact_details\",\n",
        "    \"data_source\",\n",
        "    \"fine_classification\",\n",
        "    \"notes\",\n",
        "    \"description\",\n",
        "    \"STIX_supported\",\n",
        "    \"proprietary_artifact\",\n",
        "    \"parser\",\n",
        "]\n",
        "\n",
        "# 4) Reindex to pull in those cols, filling missing with None\n",
        "df = df.reindex(columns=wanted, fill_value=None)\n",
        "\n",
        "# --- Added step: Remove duplicates based on 'observable_value' ---\n",
        "# This ensures that when 'observable_value' is set as the index, it is unique.\n",
        "# 'keep='first'' keeps the first occurrence of each duplicate value.\n",
        "df = df.drop_duplicates(subset=['observable_value'], keep='first')\n",
        "print(\"Duplicate 'observable_value' entries removed (keeping first occurrence).\")\n",
        "# --- End of added step ---\n",
        "\n",
        "\n",
        "# 5) Export as a JSON object keyed by observable_value\n",
        "# This will now work without error because the index is unique.\n",
        "df.set_index(\"observable_value\") \\\n",
        "  .to_json(\n",
        "     \"observables_by_value.json\",\n",
        "     orient=\"index\",\n",
        "     indent=2,\n",
        "     force_ascii=False\n",
        "  )\n",
        "\n",
        "# 6) Download the result\n",
        "files.download(\"observables_by_value.json\")\n",
        "\n",
        "print(f\"JSON saved to observables_by_value.json\")"
      ],
      "metadata": {
        "id": "TBgl6ml96vLz",
        "outputId": "0cd63637-699c-487c-edee-c0a6758c2c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate 'observable_value' entries removed (keeping first occurrence).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8582baea-0dc5-47f0-ad65-c47bf42673d2\", \"observables_by_value.json\", 325145)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON saved to observables_by_value.json\n"
          ]
        }
      ]
    }
  ]
}