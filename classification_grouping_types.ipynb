{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorinhazan/FinalProject-DataScience/blob/main/classification_grouping_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "from striprtf.striprtf import rtf_to_text"
      ],
      "metadata": {
        "id": "dsdIkZocIcwQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aX3QUVycYhLZ"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# !pip install --upgrade openai\n",
        "# !pip install striprtf --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load the RTF\n",
        "with open(\"token_api_final_proj.rtf\", \"r\", encoding=\"utf-8\") as f:\n",
        "    rtf = f.read()\n",
        "\n",
        "key = rtf_to_text(rtf).strip()\n",
        "os.environ[\"OPENAI_API_KEY\"] = key\n",
        "\n",
        "print(\"OPENAI_API_KEY loaded:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
      ],
      "metadata": {
        "id": "ij9SNWbz_WJA",
        "outputId": "e2978e19-36e8-4520-c1ca-8e7dc2f82eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_ranking_path = \"merged_ranking.txt\"\n",
        "ranking_res_zip = \"/content/ranking_results.zip\"\n",
        "\n",
        "with zipfile.ZipFile(ranking_res_zip, 'r') as z, open(results_ranking_path, 'w', encoding='utf-8') as out:\n",
        "    for info in z.infolist():\n",
        "        if info.filename.endswith('.txt'):\n",
        "            out.write(f\"===== {info.filename} =====\\n\")\n",
        "            with z.open(info) as f:\n",
        "                for raw in f:\n",
        "                    out.write(raw.decode('utf-8', errors='replace'))\n",
        "            out.write(\"\\n\\n\")\n",
        "\n",
        "print(f\"Done — all .txt merged into `{results_ranking_path}`\")\n"
      ],
      "metadata": {
        "id": "5Vlc-kLBY2D2",
        "outputId": "cb456351-5c64-4ff0-e66f-f1b815c42515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ranking_results.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-37851676025c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mranking_res_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/ranking_results.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranking_res_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_ranking_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ranking_results.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs_res_zip        = '/content/json_results.zip'\n",
        "extract_dir     = '/content/extracted_jsons'\n",
        "merged_json_path = 'merged_obs_extraction.json'\n",
        "\n",
        "with zipfile.ZipFile(obs_res_zip, 'r') as zf:\n",
        "    zf.extractall(extract_dir)\n",
        "\n",
        "# 3. Merge into one dictionary, extending duplicates’ observables\n",
        "merged_report_results = {}\n",
        "for filename in os.listdir(extract_dir):\n",
        "    # only process .json files\n",
        "    if not filename.lower().endswith('.json'):\n",
        "        continue\n",
        "\n",
        "    full_path = os.path.join(extract_dir, filename)\n",
        "    with open(full_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for md_name, doc in data.items():\n",
        "        if md_name not in merged_report_results:\n",
        "            merged_report_results[md_name] = doc\n",
        "        else:\n",
        "            # extend observables list from both\n",
        "            merged_report_results[md_name][\"observables\"].extend(doc.get(\"observables\", []))\n",
        "            # you can merge other fields here if needed\n",
        "\n",
        "with open(merged_json_path, 'w') as f:\n",
        "    json.dump(merged_report_results, f, indent=2)"
      ],
      "metadata": {
        "id": "c1sBAQkEIf1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Classification Groups"
      ],
      "metadata": {
        "id": "Rwm2ySjnkqK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_json_path = 'merged_obs_extraction.json'\n",
        "with open(merged_json_path, 'r', encoding='utf-8') as f:\n",
        "    merged_obs_extraction = json.load(f)"
      ],
      "metadata": {
        "id": "SUQRxhyCz4DE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract, lowercase, and dedupe classification values\n",
        "unique_classifications = {\n",
        "    obs['classification'].lower()\n",
        "    for doc in merged_obs_extraction.values()\n",
        "    for obs in doc.get('observables', [])\n",
        "    if 'classification' in obs\n",
        "}"
      ],
      "metadata": {
        "id": "lX-6rcQ3IgXz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_classifications.update(['api',\n",
        " 'api call',\n",
        " 'api function',\n",
        " 'api hook',\n",
        " 'archive file',\n",
        " 'attack effect',\n",
        " 'attack technique',\n",
        " 'authentication credential',\n",
        " 'authentication technique',\n",
        " 'boot record',\n",
        " 'c2 server',\n",
        " 'circuit breaker',\n",
        " 'code snippet',\n",
        " 'command',\n",
        " 'command line argument',\n",
        " 'command message',\n",
        " 'command parameters',\n",
        " 'command sequence',\n",
        " 'command value',\n",
        " 'command/utility',\n",
        " 'communication channel',\n",
        " 'communication interface',\n",
        " 'communication port',\n",
        " 'communication priority level',\n",
        " 'communication protocol',\n",
        " 'config/data file',\n",
        " 'configuration data',\n",
        " 'configuration file',\n",
        " 'configuration parameter',\n",
        " 'credential',\n",
        " 'credential list',\n",
        " 'data',\n",
        " 'data block',\n",
        " 'data manipulation',\n",
        " 'data transfer',\n",
        " 'database server',\n",
        " 'device',\n",
        " 'device configuration value',\n",
        " 'device state',\n",
        " 'device status parameter',\n",
        " 'distributed control system',\n",
        " 'dll file',\n",
        " 'document',\n",
        " 'domain name',\n",
        " 'driver file',\n",
        " 'dynamic-link library',\n",
        " 'electrical device',\n",
        " 'email message',\n",
        " 'error state',\n",
        " 'event log',\n",
        " 'executable command',\n",
        " 'executable file',\n",
        " 'exploit payload',\n",
        " 'exploit technique',\n",
        " 'facility',\n",
        " 'file',\n",
        " 'file type',\n",
        " 'file/script',\n",
        " 'firewall rule',\n",
        " 'firewall utility',\n",
        " 'firmware',\n",
        " 'frequency converter drive',\n",
        " 'function block memory location',\n",
        " 'hardware component',\n",
        " 'hex value',\n",
        " 'hmi device',\n",
        " 'host device',\n",
        " 'http request',\n",
        " 'ics address',\n",
        " 'ics application',\n",
        " 'ics command',\n",
        " 'ics command message',\n",
        " 'ics communication payload',\n",
        " 'ics communication protocol',\n",
        " 'ics configuration',\n",
        " 'ics configuration file',\n",
        " 'ics controller',\n",
        " 'ics data',\n",
        " 'ics data block recording',\n",
        " 'ics device',\n",
        " 'ics device parameter',\n",
        " 'ics field',\n",
        " 'ics function block',\n",
        " 'ics gateway',\n",
        " 'ics i/o snapshot',\n",
        " 'ics network communication',\n",
        " 'ics object',\n",
        " 'ics parameter',\n",
        " 'ics payload component',\n",
        " 'ics process data',\n",
        " 'ics project file',\n",
        " 'ics protocol',\n",
        " 'ics protocol field',\n",
        " 'ics protocol module',\n",
        " 'ics protocol parameter',\n",
        " 'ics protocol value',\n",
        " 'ics software module',\n",
        " 'ics systems',\n",
        " 'ics tag',\n",
        " 'identifier constant',\n",
        " 'impact condition',\n",
        " 'industrial communication protocol',\n",
        " 'industrial control device',\n",
        " 'industrial control module',\n",
        " 'industrial control system',\n",
        " 'industrial control system (ics) device',\n",
        " 'industrial control system device',\n",
        " 'industrial control system platform',\n",
        " 'industrial controller (cpu)',\n",
        " 'industrial network bus',\n",
        " 'integrity check routine',\n",
        " 'log files',\n",
        " 'malicious file',\n",
        " 'malicious ics function block',\n",
        " 'malicious logic',\n",
        " 'malicious software',\n",
        " 'malware',\n",
        " 'malware module',\n",
        " 'manufacturing facility',\n",
        " 'medical product',\n",
        " 'memory access pattern',\n",
        " 'memory access request',\n",
        " 'memory write attempt',\n",
        " 'module',\n",
        " 'monitor',\n",
        " 'network communication',\n",
        " 'network communication technique',\n",
        " 'network configuration',\n",
        " 'network connection',\n",
        " 'network data',\n",
        " 'network device',\n",
        " 'network entity',\n",
        " 'network identifier',\n",
        " 'network packet',\n",
        " 'network port',\n",
        " 'network protocol',\n",
        " 'network segment',\n",
        " 'network service',\n",
        " 'network service/port',\n",
        " 'network traffic',\n",
        " 'network traffic event',\n",
        " 'opc server',\n",
        " 'opc ua address space',\n",
        " 'opc ua server',\n",
        " 'operating system api',\n",
        " 'operational mode',\n",
        " 'os system call',\n",
        " 'packaging tool',\n",
        " 'payload file',\n",
        " 'plc',\n",
        " 'plc block',\n",
        " 'plc code',\n",
        " 'plc code component',\n",
        " 'plc cpu',\n",
        " 'plc data block',\n",
        " 'plc data block content (magic value)',\n",
        " 'plc device',\n",
        " 'plc function block',\n",
        " 'plc i/o image',\n",
        " 'plc operating system',\n",
        " 'plc organization block',\n",
        " 'plc program organization unit',\n",
        " 'plc runtime constraint',\n",
        " 'process',\n",
        " 'process name list',\n",
        " 'process termination',\n",
        " 'profibus communication module',\n",
        " 'program transfer operation',\n",
        " 'project file',\n",
        " 'protective relay',\n",
        " 'protocol',\n",
        " 'protocol field',\n",
        " 'protocol object data',\n",
        " 'protocol version',\n",
        " 'proxy server',\n",
        " 'python function call',\n",
        " 'registry key',\n",
        " 'remote access service',\n",
        " 'remote terminal unit',\n",
        " 'removable media',\n",
        " 'resource identifier',\n",
        " 'safety instrumented system',\n",
        " 'script',\n",
        " 'script engine/interpreter',\n",
        " 'script file',\n",
        " 'script framework',\n",
        " 'sensor reading',\n",
        " 'serial port',\n",
        " 'server',\n",
        " 'server information',\n",
        " 'service control',\n",
        " 'service/process',\n",
        " 'servo drive',\n",
        " 'shellcode',\n",
        " 'signature value',\n",
        " 'software/program',\n",
        " 'software/tool',\n",
        " 'software/tool (malware)',\n",
        " 'sql command',\n",
        " 'sql stored procedure',\n",
        " 'storage device',\n",
        " 'string',\n",
        " 'url',\n",
        " 'user account',\n",
        " 'variable state',\n",
        " 'vulnerability',\n",
        " 'vulnerability identifier',\n",
        " 'web script',\n",
        " 'windows registry key'])"
      ],
      "metadata": {
        "id": "y7LvUuSXzMyO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gross_classifications = set([\n",
        "\"System\",\n",
        "\"Module\",\n",
        "\"Hardware\",\n",
        "\"Device\",\n",
        "\"PLC\",\n",
        "\"POU\",\n",
        "\"Identifier\",\n",
        "\"Information\",\n",
        "\"Credential\",\n",
        "\"Data\",\n",
        "\"Command\",\n",
        "\"API\",\n",
        "\"Code\",\n",
        "\"Process\",\n",
        "\"Configuration\",\n",
        "\"Log\",\n",
        "\"File\",\n",
        "\"Payload\",\n",
        "\"Software\",\n",
        "\"Service\",\n",
        "\"Firmware\",\n",
        "\"Server\",\n",
        "\"Communication\",\n",
        "\"Protocol\",\n",
        "\"Protocol Field\",\n",
        "\"Connection Port\",\n",
        "\"Vulnerability\",\n",
        "\"Attack Technique\"])"
      ],
      "metadata": {
        "id": "1n3QQILtIjC0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_grouping_prompt = f\"\"\"\n",
        "You are a cybersecurity analyst expert. Your job is to group a list of observable “classification” labels under gross classifications from MITRE ATT&CK® Enterprise, or if not matched to any existing gross classification - create a new category that matches the observable group.\n",
        "\n",
        "---\n",
        "### Input\n",
        "   - A set of unique observable classifications:\n",
        "     {sorted(unique_classifications)}\n",
        "\n",
        "   - A set of gross classifications from MITRE ATT&CK® Enterprise:\n",
        "     {sorted(gross_classifications)}\n",
        "\n",
        "---\n",
        "### Task\n",
        "   - For each unique observable classifications, choose exactly one gross classification it best fits.\n",
        "   - If it does not clearly belong to any of the gross classification labels given, assign it to a new category of your own choosing, appending “– new” to that category name (e.g. “Data Management – new”).\n",
        "\n",
        "---\n",
        "### Output\n",
        "   - Return **only** a single JSON object.\n",
        "   - Do **not** include any words outside of that JSON—no explanations, no commentary.\n",
        "   - Do **not** add free text; only JSON format.\n",
        "   - Each key must be either one of the 28 gross classification label names or one of your “– new” categories.\n",
        "   - Each value must be an array of the unique observable classifications assigned to that key.\n",
        "\n",
        "---\n",
        "### Response format)\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"Code\": [\n",
        "    \"script file\"\n",
        "  ],\n",
        "  \"Command\": [\n",
        "    \"command string\"\n",
        "  ],\n",
        "  \"Identifier\": [\n",
        "    \"ip address\",\n",
        "    \"domain\"\n",
        "  ],\n",
        "  \"Data\": [\n",
        "    \"file format\",\n",
        "    \"file signature\"\n",
        "  ]\n",
        "  ...\n",
        "}}\n",
        "\n",
        "##\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yhVtjRmUIk2l"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],  # or however you load it\n",
        ")\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"o3-mini-2025-01-31\",          # ← swap in your desired model\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful cybersecurity expert.\"},\n",
        "        {\"role\": \"user\",   \"content\": classification_grouping_prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Extract the raw JSON string from the assistant’s reply\n",
        "raw = response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "7q4vsN_vIoTY"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip out any leading/trailing whitespace\n",
        "clean_response = raw.strip()\n",
        "\n",
        "# We look for the first `{` and the last `}`\n",
        "start = clean_response.find('{')\n",
        "end   = clean_response.rfind('}')\n",
        "if start != -1 and end != -1:\n",
        "    clean_response = clean_response[start:end+1]\n",
        "\n",
        "groups_mapping = json.loads(clean_response)\n",
        "with open(\"groups_mapping.json\", \"w\") as f:\n",
        "    json.dump(groups_mapping, f, indent=2)\n",
        "\n",
        "print(\"groups_mapping.json written\")"
      ],
      "metadata": {
        "id": "ccKVpONCP5ln",
        "outputId": "21003deb-de97-49fe-cb69-e29481c9861d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "groups_mapping.json written\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build reverse map: sub-classification (lowercase) → gross group name\n",
        "reverse_map = {}\n",
        "for gross_group, sub_list in groups_mapping.items():\n",
        "    for sub in sub_list:\n",
        "        reverse_map[sub.lower()] = gross_group\n"
      ],
      "metadata": {
        "id": "x56qNZhgVmDM"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename column and extract only the relavent for comprison"
      ],
      "metadata": {
        "id": "2CI6w7k0mEk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output_path = 'merged_obs_extraction_renamed.json'\n",
        "\n",
        "# Iterate over each file and its observables, renaming keys as requested\n",
        "for filename, content in merged_obs_extraction.items():\n",
        "    for obs in content.get('observables', []):\n",
        "        if 'observable_rank' in obs:\n",
        "            obs['artifact_details'] = obs.pop('observable_rank')\n",
        "        if 'classification' in obs:\n",
        "            obs['fine_classification'] = obs.pop('classification')\n",
        "\n",
        "# # Save the updated JSON to a new file\n",
        "# with open(output_path, 'w') as f:\n",
        "#     json.dump(merged_obs_extraction, f, indent=2)\n",
        "\n",
        "# print(f\"Renamed keys and saved the updated JSON to '{output_path}'\")"
      ],
      "metadata": {
        "id": "s0ZFcvPgXxRd"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_obs_extraction_renamed_path = \"/content/merged_obs_extraction_renamed.json\"\n",
        "# with open(merged_obs_extraction_renamed_path, 'r') as f:\n",
        "#     merged_obs_extraction_renamed = json.load(f)"
      ],
      "metadata": {
        "id": "gcsT2J7-T2Sc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4) Annotate each observable\n",
        "for doc_name, doc_data in merged_obs_extraction.items():\n",
        "    for obs in doc_data.get('observables', []):\n",
        "        # print(doc_data.get('observables', []))\n",
        "        cls = obs.get('fine_classification', '').lower()\n",
        "        # print(cls)\n",
        "        # look up the group, default to 'Unknown' if not found\n",
        "        obs['gross_classification'] = reverse_map.get(cls, 'Unknown')\n",
        "\n",
        "# 5) Save the enriched JSON\n",
        "out_path = '/content/merged_with_gross_classification-reports.json'\n",
        "with open(out_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(merged_obs_extraction, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Done—saved annotated file to {out_path}\")"
      ],
      "metadata": {
        "id": "Fh0pvZrTSqyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41df7183-21a4-40e2-cfc5-35fd2b059dd0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done—saved annotated file to /content/merged_with_gross_classification-reports.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert csv table into json object in order to compare between observables and add `gross_classification` col"
      ],
      "metadata": {
        "id": "YTY82kO8nlJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/updated_Procedure_descriptions_observables_using_o3_mini_prompt_with_deprecation.csv\"\n",
        "observables_porc_desc_df = pd.read_csv(csv_path)\n",
        "\n",
        "observables_porc_desc_df = observables_porc_desc_df.rename(columns={\"classification\": \"fine_classification\"})\n",
        "\n",
        "wanted = [\n",
        "    \"observable_value\",\n",
        "    \"artifact_details\",\n",
        "    \"data_source\",\n",
        "    \"fine_classification\",\n",
        "    \"notes\",\n",
        "    \"description\",\n",
        "    \"STIX_supported\",\n",
        "    \"proprietary_artifact\",\n",
        "    \"parser\",\n",
        "]\n",
        "\n",
        "# Reindex (fills any missing with None)\n",
        "observables_porc_desc_df = observables_porc_desc_df.reindex(columns=wanted, fill_value=None)\n",
        "\n",
        "# Drop duplicates on observable_value\n",
        "observables_porc_desc_df = observables_porc_desc_df.drop_duplicates(subset=['observable_value'], keep='first')\n",
        "\n",
        "# Add gross_classification via vectorized map\n",
        "observables_porc_desc_df['gross_classification'] = (\n",
        "    observables_porc_desc_df['fine_classification']\n",
        "      .str.lower()\n",
        "      .map(reverse_map)      # make sure you’ve defined reverse_map earlier\n",
        "      .fillna('Unknown')\n",
        ")\n",
        "\n",
        "observables_porc_desc_df.set_index(\"observable_value\") \\\n",
        "    .to_json(\n",
        "       \"observables_by_value.json\",\n",
        "       orient=\"index\",\n",
        "       indent=2,\n",
        "       force_ascii=False\n",
        "    )\n",
        "\n",
        "out_path = '/content/merged_with_gross_classification-table.json'\n",
        "records = observables_porc_desc_df.to_dict(orient='records')\n",
        "with open(out_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Saved annotated file to {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFGXg-6InhvR",
        "outputId": "790a3250-215a-44e0-fb3c-d0890465bd99"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved annotated file to /content/merged_with_gross_classification-table.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_CUX2Xnpjhf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}