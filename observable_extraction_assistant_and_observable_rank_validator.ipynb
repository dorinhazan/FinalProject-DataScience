{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorinhazan/FinalProject-DataScience/blob/main/observable_extraction_assistant_and_observable_rank_validator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/validation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNn-Z-IhdyR5",
        "outputId": "0ead70fa-234a-4eff-9aa2-32e882ed54e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/validation.zip\n",
            "   creating: validation/\n",
            "  inflating: __MACOSX/._validation   \n",
            "  inflating: validation/results-reports-new-prompt.json  \n",
            "  inflating: __MACOSX/validation/._results-reports-new-prompt.json  \n",
            "  inflating: validation/%5BAnalysis%5DAndariel_Group.md  \n",
            "  inflating: __MACOSX/validation/._%5BAnalysis%5DAndariel_Group.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY=\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mLhZTB-0sh1",
        "outputId": "43a8b29c-0bb2-4942-f862-f219204f2709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import regex as re\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key = api_key)"
      ],
      "metadata": {
        "id": "B1ou25wvhCap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing images from the Markdown files"
      ],
      "metadata": {
        "id": "oYY2RMA6QaBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_markdown(file_path):\n",
        "    \"\"\"\n",
        "    Clean a single Markdown file by removing hyperlinks, annotations, headers, and footers.\n",
        "    Args:\n",
        "        file_path (str): Path to the Markdown file.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        content = file.read()\n",
        "\n",
        "\n",
        "    # Patterns for removal\n",
        "    patterns = {\n",
        "        \"inline_hyperlinks\": r'\\[.*?\\]\\(http[s]?://\\S+?\\)',  # Matches [text](http://example.com)\n",
        "        \"standalone_urls\": r'http[s]?://\\S+',  # Matches http://example.com\n",
        "        # \"annotations\": r'\\[\\]\\(\\S+\\)',  # Matches empty image annotations like []()\n",
        "        \"headers_footers\": r'(Recommended Practice|Homeland Security|Page \\d+)',  # Matches headers/footers\n",
        "        \"images\": r'!\\[[^\\]]*\\]\\((?:[^()\\\\]|\\\\.)*?\\)', # Matches image anotation like ![alt text](url “optional title”)\n",
        "    }\n",
        "\n",
        "    # Debugging: Print content before cleaning\n",
        "\n",
        "    for name, pattern in patterns.items():\n",
        "        matches = re.findall(pattern, content)\n",
        "        print(matches)\n",
        "        content = re.sub(pattern, '', content)\n",
        "\n",
        "\n",
        "    # Save the cleaned content\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(content)\n"
      ],
      "metadata": {
        "id": "cHEqF4QZgn8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_markdown(\"/content/validation/%5BAnalysis%5DAndariel_Group.md\")"
      ],
      "metadata": {
        "id": "wWe4K68fh5wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba17291-0407-4b2e-f0e2-eeff62c93e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corected Code - gpt_for_reports.py\n"
      ],
      "metadata": {
        "id": "dtEycUnyFyFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs_rank_validator_instructions = \"\"\"\n",
        "\n",
        "# Observable-rank Validator\n",
        " You are a senior CTI analyst. Your job is to **audit one observable at a time** and judge whether its `observable_rank` value (“Actionable”, “Described”, or “Mentioned”) is correct, based on the observable’s name and the provided context.\n",
        ">\n",
        "> You will receive:\n",
        "> 1. The observable record (as JSON).\n",
        "> 2. The surrounding sentence or paragraph from the original CTI snippet for minimal context (when available).\n",
        "\n",
        "### 1.  Decision Rules\n",
        "\n",
        "| Rank              | Decide “Actionable” **when …**                                                                                                                   | Typical examples (not exhaustive)                                                                         |\n",
        "|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
        "| **Actionable**    | • The exact string can be matched **as‑is** (or after a trivial transform like Base64 decode).<br>• A detection rule (IDS/YARA/SIEM, PLC logic, etc.) could key on it with low false‑positives.<br>• Uniqueness is obvious (or highly likely) from its syntax or entropy. | – Full code snippets / shell commands / SQL queries<br>– Complete URLs, URIs, or file paths<br>– IPs, domains, GUIDs, hashes (MD5/SHA‑256/SHA‑1, Cert thumbprints), JWTs, beacon keys<br>– Hard‑coded strings, mutexes, registry keys, ICS/SCADA tags, Modbus function codes<br>– Crypto keys, X.509 DN strings, email addresses, phone numbers used for C2 |\n",
        "| **Described**     | • The details are not sufficient to act upon **or** the observable is not searchable, for example, due to ambiguity or missing information.<br>• Additional enrichment (lookup table, parameter substitution, memory carving, etc.) is required **and** is non‑trivial. | – “An HTTP POST to `/api/checkin?id=<random>`” (placeholder)<br>– “A PowerShell script that loads shellcode” (no code shown)<br>– “A DLL named similar to system files” |\n",
        "| **Mentioned**     | • It is only referenced conceptually or generically and **cannot** be turned into a concrete detection even after enrichment.                    | – “Uses AES‑128” (algorithm only)<br>– “Makes RPC calls” (no function names)<br>– “Phishing email” |\n",
        "\n",
        "### 2.  Key Heuristics\n",
        "\n",
        "1. **Code fence = Actionable**\n",
        "   Any observable whose `observable_value` is wrapped in triple back‑ticks is presumed actionable *unless* it is clearly pseudocode.\n",
        "\n",
        "2. **Complete identifier = Actionable**\n",
        "   A string that *looks complete* for its type (e.g., 36‑char GUID, 64‑hex SHA‑256, “10.0.0.5”, “plc_tag=3001:1”) is actionable.\n",
        "\n",
        "3. **Indicator Strings**\n",
        "   Strings such as `\"S^Anonymous?\"`, mutex names, task names, beacon keys, campaign IDs, etc., are actionable if they appear exactly.\n",
        "\n",
        "4. **Encoded Artifacts**\n",
        "   If a value is Base64/hex/URL‑encoded **and its decoded form is also supplied**, both entries are independently actionable.\n",
        "\n",
        "5. **When unsure**\n",
        "   Err toward **higher precision**:\n",
        "   ```\n",
        "   Actionable  >  Described  >  Mentioned\n",
        "   ```\n",
        "   If the observable *could plausibly* drive automated detection, choose **Actionable**.\n",
        "\n",
        "### 3.  Output Format\n",
        "\n",
        "Respond only with one of the following, for each observable:\n",
        "\n",
        "```text\n",
        "CORRECT\n",
        "```\n",
        "\n",
        "```text\n",
        "INCORRECT — should be \"<CorrectRank>\" because <one‑sentence justification>, note: \"<copy 'note' field from observable record>\"\n",
        "```x\n",
        "\n",
        "***(No other words.)***\n",
        "\n",
        "---\n",
        "\n",
        "### 4.  Quick Examples for Output Format\n",
        "\n",
        "| Observable (value + rank) | Validator output | Rationale |\n",
        "|---------------------------|------------------|-----------|\n",
        "| ```send_403070(0x1Au,0…)``` → **Described** | `INCORRECT — should be \"Actionable\" because it is a full, unique code snippet that can be matched directly.` | Rule 1 |\n",
        "| `aHR0cHM6Ly9jdC5lemlsLmNvbS9wYXlsb2Fk` (encoded) → **Actionable** | `CORRECT` | Encoded, unique, searchable |\n",
        "| `“a DLL named netutils.dll”` → **Mentioned** | `INCORRECT — should be \"Described\" because it gives a partial but still ambiguous filename pattern.` | lacks uniqueness |\n",
        "| `AES‑128` → **Mentioned** | `CORRECT` | Only an algorithm, non‑searchable |\n",
        "\n",
        "---\n",
        "\n",
        "Use these instructions as the **sole evaluation rubric**.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5ZxsnayUOCpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs_rank_validator_ID = \"asst_ksYtNJ5GTGYvwNQS6liBckyN\"\n",
        "our_updated_assistant = client.beta.assistants.update(\n",
        "  obs_rank_validator_ID,\n",
        "  instructions=obs_rank_validator_instructions,\n",
        ")\n",
        "# Notice! this code will update the assistant in OpenAI, so next time you will run the code at the beggining of this notebook, in will call the updated assistant"
      ],
      "metadata": {
        "id": "dBo6i6BxupGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# obs_rank_validator_ID = \"asst_ksYtNJ5GTGYvwNQS6liBckyN\"\n",
        "\n",
        "def observable_rank_validator(observables):\n",
        "\n",
        "  \"\"\"\n",
        "  Validating your Observable Extraction using an observable-rank validator.\n",
        "\n",
        "  This function uses an OpenAI assistant I built for you, named Observable-Rank Validator, its purpose\n",
        "  is to help you to validate your result from the observable extractor assistant.\n",
        "  This function receives a list of observables (a JSON list of observables, as resulted from the Observable Extractor Assistant),\n",
        "  and Respond with one of the two:\n",
        "\n",
        "    ```text\n",
        "    CORRECT\n",
        "    ```\n",
        "\n",
        "    ```text\n",
        "    INCORRECT — should be \"<CorrectRank>\" because <one‑sentence justification>\n",
        "    ```\n",
        "  for each observable in the list, according to their order.\n",
        "\n",
        "  \"\"\"\n",
        "  payload = json.dumps(observables, ensure_ascii=False, indent=2)\n",
        "\n",
        "  # 2️⃣ Optionally wrap in a ```json code-fence if that’s how the assistant was trained\n",
        "  user_msg = (\n",
        "      \"Here is a JSON list of observables. \"\n",
        "      \"Validate the `observable_rank` of each one.\\n\"\n",
        "      \"```json\\n\" + payload + \"\\n```\"\n",
        "  )\n",
        "\n",
        "  # 3️⃣ Create the thread / run\n",
        "  thread = client.beta.threads.create(\n",
        "      messages=[{\"role\": \"user\", \"content\": user_msg}],\n",
        "  )\n",
        "\n",
        "  run = client.beta.threads.runs.create_and_poll(\n",
        "      thread_id    = thread.id,\n",
        "      assistant_id = obs_rank_validator_ID\n",
        "  )\n",
        "\n",
        "  if run.status != \"completed\":\n",
        "      raise RuntimeError(f\"Validator run ended with status {run.status}\")\n",
        "\n",
        "  reply = client.beta.threads.messages.list(thread_id=thread.id).data[0]\n",
        "  return reply.content[0].text.value"
      ],
      "metadata": {
        "id": "gN4-Bq7rF6xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XuctPPO1dhD2",
        "outputId": "bdf7861b-9d56-4dd7-d4d4-b3d4ece9fa94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 markdown files.\n",
            "\n",
            "Processing file: /content/validation/%5BAnalysis%5DAndariel_Group.md\n",
            "['Analysis Report (الران\\n\\n', '# Targeted attacks by Andariel Threat Group, a subgroup of the Lazarus\\n\\n\\n\\n220, Pangyoyeok-ro, Bundang-gu, Seongnam-si, Gyeonggi-do, South Korea Tel: +82-31-722-8000 | Fax: +82-31-722-8901 | www.ahnlab.com | © AhnLab, Inc. All rights reserved.\\n\\n', \"## Table of Contents\\n\\n| Overview |\\n| --- |\\n| Attack Vectors (Infection Routes). |\\n| 1. Spear Phishing |\\n| 2. Watering Hole (Active-X Vulnerability) |\\n| 3. Central Manaqement Solution . |\\n| 4. Supply Chain Attack . |\\n| Attack Cases . |\\n| Malware and Attack Tools . |\\n| 1. Malware – Backdoor …………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………… 11 |\\n| 1.1) Aryan . |\\n| 1.2) Gh0st RAT . |\\n| 1.3) Rifdoor………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………… 12 |\\n| 1.4) Phandoor |\\n| 1.5) Andaratm |\\n| 2. Attack Tools. |\\n| Similarities in Multiple Attack Cases |\\n| AhnLab's Response. |\\n| Conclusion . |\\n| Reference |\\n\\n\", '## Overview\\n\\nThe Andariel group is a subgroup of the Lazarus group that has been active since 2015. Andariel has a connection to the cyber-attack named Operation Black Mine that occurred in 2014 and 2015. However, Operation Black Mine is also associated with the attacks on the South Korean Military Agency in 2008 and the attacks against South Korean banks and broadcastersin 2013 (a.k.a DarkSeoul).\\n\\nThe major targets of the Andariel Group include not only military agencies, defense industries, political organizations, security companies, ICT companies, and energy research institutes, but also financial targets, such as ATMs, banks, travel agencies, cryptocurrency exchanges, and online qambling users.\\n\\nTheir main methods of attacks are spear phishing using macros, watering hole attacks exploiting Active-X vulnerabilities, vulnerability exploits on security and IT asset management systems, and supply chain attacks.\\n\\nThe group makes use of well-known backdoors, such as Aryan and Gh0st RAT, but also uses self-developed backdoors, such as Andarat, Andaratm, Rifdoor, and Phandoor. Furthermore, this group appears to know Korean language and its IT environment.\\n\\nThis report examines the attacks by Andariel Threat Group, including key methods, and changes in their purpose and targets.\\n\\n', '# Attack Vectors (Infection Routes)\\n\\nThe Andariel group uses a variety of attack techniques, and, in particular, they take advantage of vulnerabilities of local software in South Korea.\\n\\n\\n\\n[Figure 1] Major attack vectors of the Andariel group\\n\\n', '## 1. Spear Phishing\\n\\nThe Andariel group uses the spear phishing method by understanding their target and sending emails with an attachment that appears to be from a relevant, seemingly trustworthy source. The attachments contain macro and trick the targeted recipient into activating the macro. However, this method of inducing macro activation has become more devious after 2015.\\n\\n[Figure 2] below shows the contents of attachments used in the 2015 attacks with the original method of inducing macro activation. The user can enable macro, but there is not a significant need to do so because the content is visible.\\n\\n\\n\\n[Figure 2] Contents of documents used in the 2015 attack\\n\\nHowever, malicious attachments found since 2017 show a new method. The contents of documents are blurred, as shown in [Figure 3], as if there is a problem with the display, increasing the likelihood of the recipients enabling the macros.\\n\\n| 4499 100 | IT NEWS CORRESS & DESIGNALS - PER OF | Class of Contract of Concession | CALL COLLECTION CONNECT CONTRA |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- |\\n| MART REE-HERTICH FOR FOR FOR AN | NAMERANANA AND ENGLES OF LEE LE FOR |  |  |  |  |  |  |\\n| CHILANDERS TO | (图书)(( 图文教育馆(Jan |  |  |  |  |  |  |\\n| 64 & 14-50 | 14 | 144 | 1-40-47 | that county of the 201 . A | 1 80 3 11 8 8 1 4 | 13.44 | 10.00 100 |\\n| 1011/478-104 | CHANGE CARDED OF | relation of other considera |  |  |  |  |  |\\n| MILLERS LEASE & LEASE & | 1989 | (1-07-21-18 17) Statist (1) 1 | 18.40 | 100 110 000 | 0-0-0-0-0-00 | 1000 mg connect bentifications of the | I |\\n\\n[Figure 3] Contents of documents used in the 2017 attack\\n\\n', '## 2. Watering Hole (Active-X Vulnerability)\\n\\nThe Andariel group also uses the watering hole technique, which compromise and inject exploit codes into a website. The targeted systems are infected with malware upon accessing the compromised website using a vulnerable web browser. These attacks also limit infection to specific IP address ranges, making it much more difficult to identify the attack targets.\\n\\nFor the watering hole attack, the group usually embeds an Active-X vulnerability exploit codes in the target website. When the target accesses the website via an Internet Explorer browser with a specific Active-X installed the attack proceeds. After successful exploitation of the vulnerability, a JavaScript or VBScript file is created on the user system and this file downloads the malware from a specified address.\\n\\n| function getXMLHI tpRequest() |\\n| --- |\\n| tryingturn new Act (vaXObject( Moxel 2 XMLHTTP. 6.0 ) ) |\\n| catcheal (itry(return new Active)(b) == ( \"Msxall INLHTF 5.0\") ) |\\n| catch(@2) tryireturn new ActiveXObject   Msxm)2,XMLHTP,4,0\");} |\\n| catch(eS) itryireturn new Active XOblect   Msxm12 IMLHITP.3.0 ); } |\\n| catch(e4)itry(return new ActiveXObject) Mixw12.XMLHIP ) .; |\\n| catch(e5){tryIreturn new ActiveXObject( Microsoft. XMLHIIP ); J |\\n| catch(ab) fratuen null 193112 |\\n| Var sepat XML Hitp Requess () : |\\n| var Smage Act IveXOblect(\"ADGE Strega\"); |\\n| S. Ispe= = = = = |\\n| x. Opent Get . \" /rss sit . 0): |\\n| x. Send() = |\\n| S. Open();S. Frite(s. responsebody): |\\n| Var In = L 000 Indows Peters (8) = 11 Jer |\\n| var for- L Mewindows wtempor conhost the i |\\n| S. Save ToFile(1n2.2): |\\n| S.Claspl ); |\\n| var d m new Entel ). |\\n| var Hours = d set hours = |\\n| var Minutes = d. pethingtes == |\\n| var str = [c at. \" + Hours = \" = Hinutes = \" = In : |\\n| var D=new ActiveXObject(\"Shell Application\"); |\\n| 0, Sell Execute(\\' c Windows Proysteas22000 Bd.ess\", [/c \\'(acho M25 type \" + tn2 = \\') >\\' + tn1 = \"\", \\' |\\n| Q. ShellExecute(\"c\":\"WwindowsPaystems. wir,\"\",\"open\",\"0): |\\n| Q.SwillExecute( c.WWwindowsWsystes33Wcwd.axe\", \\'/c dai: C Ww indowsPiceoffludate, is . |\\n\\n[Figure 4] Script file created in the infecte\\n\\nHere, the \"MZ\" ASCII string, which represents a Windows executable file, does not exist within the file. The malware adds this text string starting with MZ from the local system to create an executable file. This method seems to be used to avoid detection by behavior-based security solutions when the executable file is downloaded.\\n\\n| - 888000000 | BBC 888 BB | 6959 | 00 B8.00 00 | B& . | BB BB | FF .FF BB | 4715 | 110 | F | a | 00000010: | 80 00 | 40.00 | 00 00.00 00 | 00 00.00 | 08 | 00 | 88 | 08 | 00000020: | 00 00 00.00 00 00 00.00 00 00 00.00 |  |  |  |  |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 1914 | 00 80 | DA 00.00 00 00 00 00 00.00 00 00 00.00 | 00000000 | BB | BH | BE | 10-110L-Hhis pr |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| 89 CO 21.88 | 81 4C CD 21 | 54 68 69.73 | 20 70 | BDBBBBBBB | BA | -12 | 67 72 | 61.60 20 63 61.6E 6E 6F 74.20 | - BSSBBBBB | 62 | 65 20 | 61- | ogram cannot be | 53 20 60.6F 64 65 2E |  |  |  |  |  |  |  |  |  |  |  |\\n| 099888808 | 72 | 75 6E | 6E 20 44 4F | 20.69 | run in DUS node | 08000070: | BB 08 08 | 24.00 00 00 00.00 | 00 FA.A0 56 84 | 88 | BE | BHORAMAr HIST |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| 000000000 | 121 | 38 57 | BE CI 38 | 57 | BE CI | 88 | S7 D1. B7 93 57 | 97 | 57 90.01 | -84-188-1887 | C1 | 38 57 D1.B7 A6 | 92 57 | 2F | 38 57 DI . B7 | 068008800 | C3 | : 0H8800880 | 38 57 B7 B9 A8 | 38 | 57 BE C1 39 57 |  |  |  |  |\\n| E | 57 83 01 | Wirrule Blering | 38 57 D1.87 97 57 98.01 | 57 01 87 AS 57 BF | - BBBBBBB B | 38 | 1991 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| BHRich BM | COBBBBER | C1 | 38 57 52.69 63 | BE . C1 | 38 | 57 00.00 00 | BBF | BB | 68 | 00000000 | 00 | 00 00 00 00 00 00 00.00 | 00 00 08,00 00 00 | 88 | PE |  |  |  |  |  |  |  |  |  |  |\\n| 090000000 | 00 00 50.45 00 00 40.01 04 | 00 7F.03 | 58 | 59 | BB | DB | LE� OHIV | 08 | 00 00 00.00 00 00 00 00 00 00 00 00 | 80 | 000008F0 | BBE | a CHOE |  |  |  |  |  |  |  |  |  |  |  |  |\\n| . | 99.63 00 | MZE V | DOY 688088 | 40 58 98 | 00.00 00 00 00 FF | 801 88 | BB | FF | 00400818: | 00 00 88 | 88 | 08 88 | 80 08 00 00 00 00 00.00 | 80 88 | 09400020 : | 00 00 00 | 00.00 00 00.00 00 00 00.00 | 80 | 99 | 1461 |  |  |  |  |  |\\n| 00400030: | 00.00 00 00.00 | 00 00 00 00 00 00 00 F8 | 88 | 1911 | 日日 | 09400040: | BA OE . 00 B4 | 09 CD 21 BB BI 4C.CD | 21 | 54 | 第十八 | 8E 1F | 68 | 00400050: | 69 73 | 67 72.61 60 20 63.61 |  |  |  |  |  |  |  |  |  |\\n| 28 | 70.72 6F | 6E | 61- | 68 | is program canno | 00%00000 | 74 20 | 62 | 65.20 | 72 | 20.44 AF | 53 | 75 | 6E.20 69 6E | 20 | I be run in DOS | 00400070 : | 60 6F 64 65.2E 8D 00 | 00 00 72 80 80 | 00 80 | 88 | 80 |  |  |  |\\n| ભિલ | BBT HBT PART PAP - | 00400080: | 56 94 BE CT 38 57 BE CT 38 | 08 BB | C1 | 38 | 57 | 57.86 | 11941-88770MC-8M | · 060088700 | B7 | d3 | 57.97 C1 38 57.01 B7 H6 57.90 | 38 57 | DOC | C1 |  |  |  |  |  |  |  |  |  |\\n| - 060000700 | DI | B7 92 | 38 57 | 57.25 | CI 38 21 BT BB HB 21 BB | C1 | 004000B0: | BE C1 | 39 57.03 | 38 | 57 | CI | 38 | 57.01 87 97 57.98 | C1 | 85 | 09YG/SOCO - | DI | 87 | 86 10 38 15 | 57.52 69.63 68.BE | C1 | 38 | 57 | mith -8MRich -B |\\n| 00 00 00.00 00 00 00 00 00 00 00 00 | - 0088899980 | GB | 00 88 | 88 | 08.00 00 00.50 45 00 | 194 | BOY 800E0 : | 08 00 | 88.40 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n\\n[Figure 5] Downloaded file (above) and 5-byte recovered file (below)\\n\\n', \"### 3. Central Management Solution\\n\\nInstitutions and companies of a certain size often manage multiple systems in their organizations, such as PCs, by connecting them to a central management solution. This central management solution is mainly responsible for Network Access Control (NAC); anti-virus management, software and hardware assets control; and patch management, and it usually provides features such as IT asset management, report generation, software distribution, and remote control.\\n\\nThe attacker identifies and analyzes the central management solution used by the target institution or company to find and exploit the vulnerability. The attacks on the central management software can be categorized into two types: management server account attacks and vulnerability attacks on agents installed in the client.\\n\\n\\n\\n[Fiqure 6] Concept diagram of the central management solution\\n\\nMost central manaqement solutions consist of a management server and a client on which the agent is installed. The management server sends batch files to the connected systems or applies policies, and remotely controls the systems. The client processes files and commands sent from the management server.\\n\\nIn the event of an attack using the manaqement server, the attacker steals the targeted administrator account and distributes malware in the place of a normal file. This is the reason for the emphasis on management of administrator accounts. Another role of the management server is to receive the security updates for commercial software from external sources (software providers) and distributes them throughout the organization. However, if a file from the external update server tampers (e.g., by hacking); an update file containing malware will be distributed throughout the company or institution via the central management server.\\n\\nThe client agent of the central management solution is responsible for receiving and executing the file transmitted from the management server. Generally, the aqent has a feature to check whether the delivered command or file is verified. To bypass this process, the attacker pretends to be the management server and sends a command to the agent.\\n\\nThe Andariel group is responsible for carrying out many attacks on central management solutions that are widely used in South Korea. The following are the cases of the group transferring malicious files exploiting the vulnerabilities of the client agent in three types of central management solution.\\n\\nThe first case is malware that exploits vulnerabilities in central management solution A, which was first discovered in 2015. When the malware is executed, the executable file, v3pscan.exe, containing malware is transmitted to the agent of central management solution A through a specified IP address and executed.\\n\\n| .0040CE00: 26 02 00 00.00 62 00 00.0E 07 0B 00.03 00 1A 00 80 0 1.8 0 + | 0040CE10: 0E 00 25 00.34 00 70 00.58 46 49 40.45 5F 52 45 4 % 4 ) 1FILE RE |  |\\n| --- | --- | --- |\\n| 0040CE20: 40 4F 54 45.5F 45 58 45.43 50 00 88.46 49 4C 45 HOTE EXECTING LLF | 00400230 . 56.50 41.56.48.30 43.39.50 27.49 46.44 47.27.23 . PATH-C: VIINDONS |  |\\n| 0040CE40: 00 00 46 49.40 45 5F 4E 41 45 3D 56 93 50 53 | VOLTILE NAME=V3PS | .0040CE50: 63 61 6E 2E.65 78 65 00.09 46 69 40.45 5F 43 4F can.exe VIFILE CO |\\n| 00400E60: 40 40 41 45,44 30 00 08,76 49 66 45,56 % 50 % RHAND-10FILE OPT | 0040CE70: 49 YF 4E 3D 31 00 00 F6.49 4C 45 2F 4F 52 73 5F TON-13BEITE ORG |  |\\n| 0040CE80; 50 KT 54 48.3D 43 39 50 27 49 YE 44 TE 2 53 00 PATH-C VAINDOWS | 0040CE90: 00 58 4A 4F.62 49 4E 46.4F 45 58 50.00 08 4A 4F 2LJ0BINFOEK1.8JU |  |\\n| 0070CEA0: 42 49 4E 4.45 58 3D 30.00 00 20 22.49 4F 52 49 BINDEX-0VDERLORI | .00400EEBO: 54.59 30 30.00 00 00 00 00 00 00 00 00 00 00 00 00 00 14-07 |  |\\n| COLOCECO: BO BO OR DO OR DO AR OR OR DO DO DO DO DO DO CO |  |  |\\n\\n[Figure 7] Remote execution command used in the attack on the central management solution A\\n\\nAttacks on the central management solution B were made between 2015 and 2017. Various types of malware were used, such as nc.exe, nt.exe, n5lic.exe, nc5rt2.exe, and Bin.exe, to exploit the management system. Also, the attacker used a method of generating a VBScript file, such as vs 1.vbs and winrm.vbs, to download malicious files.\\n\\nVariants of this malware were discovered between 2015 and 2017, which used the server IP, target system IP, download address, remote executable path, and other items as arguments to exploit systems and generate script files that downloaded malware. The generated script downloads a file from the address entered as an argument and restores 5 bytes.\\n\\n| c: work >nc Usage:main.exe ServerIP, TargetIP, DownloadUrl, RemoteFilePath, [vbScriptPath=c: |\\n| --- |\\n| Windows temp\\\\winrm.ubsInvalid License. Iry Again |\\n| c:\\\\work>nc5rt2 |\\n| Usage:main.exe LICENSE TargetIP, PORT, DownloadUrl, RemoteFilePath, LubScriptPat |\\n| h=c=\\\\windows\\\\temp\\\\winrm.ubs |\\n| c:\\\\work>bin |\\n| Usage:main.exe License TargetIP, DownloadUrl, RemoteFilePath, [vbScriptPath=c'\\\\w |\\n| indows temp\\\\us1.ubs |\\n| c=\\\\work> |\\n\\n[Figure 8] Attack tool used in the attack on the central management solution B\\n\\nThe malware that exploited the vulnerabilities in central manaqement solution C was first found in September 2016. This attack performs malicious transferring and executing of files.\\n\\n\\n\\n\\n\"]\n",
            "File split into 8 sections.\n",
            "Processing section 1 of 8\n",
            "\n",
            "--------------------------------Section 1-----------------------------------\n",
            " Analysis Report (الران\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------results-----------------------------------\n",
            "\n",
            "{\n",
            "  \"observables\": []\n",
            "}\n",
            "parsed_response type <class 'dict'>\n",
            "parsed_response {'observables': []}\n",
            "parsed_response[observables] []\n",
            "No observables extracted in this section.\n",
            "Processing section 2 of 8\n",
            "\n",
            "--------------------------------Section 2-----------------------------------\n",
            " # Targeted attacks by Andariel Threat Group, a subgroup of the Lazarus\n",
            "\n",
            "\n",
            "\n",
            "220, Pangyoyeok-ro, Bundang-gu, Seongnam-si, Gyeonggi-do, South Korea Tel: +82-31-722-8000 | Fax: +82-31-722-8901 | www.ahnlab.com | © AhnLab, Inc. All rights reserved.\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------results-----------------------------------\n",
            "\n",
            "{\n",
            "  \"observables\": [\n",
            "    {\n",
            "      \"observable_value\": \"Andariel Threat Group\",\n",
            "      \"observable_rank\": \"Mentioned\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Threat Actor\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Name of a threat actor group mentioned in the report.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"Lazarus\",\n",
            "      \"observable_rank\": \"Mentioned\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Threat Actor\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Parent threat actor group referenced in the report.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"220, Pangyoyeok-ro, Bundang-gu, Seongnam-si, Gyeonggi-do, South Korea\",\n",
            "      \"observable_rank\": \"Described\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Physical Address\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Physical address provided in contact details.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"+82-31-722-8000\",\n",
            "      \"observable_rank\": \"Described\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Telephone Number\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Telephone number provided in contact details.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"+82-31-722-8901\",\n",
            "      \"observable_rank\": \"Described\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Fax Number\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Fax number provided in contact details.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"www.ahnlab.com\",\n",
            "      \"observable_rank\": \"Actionable\",\n",
            "      \"data_source\": \"DNS logs\",\n",
            "      \"classification\": \"Domain\",\n",
            "      \"STIX_supported\": \"Full: Domain Name\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Domain extracted from the website URL.\"\n",
            "    },\n",
            "    {\n",
            "      \"observable_value\": \"AhnLab, Inc.\",\n",
            "      \"observable_rank\": \"Mentioned\",\n",
            "      \"data_source\": \"None\",\n",
            "      \"classification\": \"Company\",\n",
            "      \"STIX_supported\": \"No\",\n",
            "      \"proprietary_artifact\": \"Open/Standard Technology\",\n",
            "      \"parser\": \"N/A\",\n",
            "      \"notes\": \"Company name mentioned in the copyright notice.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "parsed_response type <class 'dict'>\n",
            "parsed_response {'observables': [{'observable_value': 'Andariel Threat Group', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Threat Actor', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Name of a threat actor group mentioned in the report.'}, {'observable_value': 'Lazarus', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Threat Actor', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Parent threat actor group referenced in the report.'}, {'observable_value': '220, Pangyoyeok-ro, Bundang-gu, Seongnam-si, Gyeonggi-do, South Korea', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Physical Address', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Physical address provided in contact details.'}, {'observable_value': '+82-31-722-8000', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Telephone Number', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Telephone number provided in contact details.'}, {'observable_value': '+82-31-722-8901', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Fax Number', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Fax number provided in contact details.'}, {'observable_value': 'www.ahnlab.com', 'observable_rank': 'Actionable', 'data_source': 'DNS logs', 'classification': 'Domain', 'STIX_supported': 'Full: Domain Name', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Domain extracted from the website URL.'}, {'observable_value': 'AhnLab, Inc.', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Company', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Company name mentioned in the copyright notice.'}]}\n",
            "parsed_response[observables] [{'observable_value': 'Andariel Threat Group', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Threat Actor', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Name of a threat actor group mentioned in the report.'}, {'observable_value': 'Lazarus', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Threat Actor', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Parent threat actor group referenced in the report.'}, {'observable_value': '220, Pangyoyeok-ro, Bundang-gu, Seongnam-si, Gyeonggi-do, South Korea', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Physical Address', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Physical address provided in contact details.'}, {'observable_value': '+82-31-722-8000', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Telephone Number', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Telephone number provided in contact details.'}, {'observable_value': '+82-31-722-8901', 'observable_rank': 'Described', 'data_source': 'None', 'classification': 'Fax Number', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Fax number provided in contact details.'}, {'observable_value': 'www.ahnlab.com', 'observable_rank': 'Actionable', 'data_source': 'DNS logs', 'classification': 'Domain', 'STIX_supported': 'Full: Domain Name', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Domain extracted from the website URL.'}, {'observable_value': 'AhnLab, Inc.', 'observable_rank': 'Mentioned', 'data_source': 'None', 'classification': 'Company', 'STIX_supported': 'No', 'proprietary_artifact': 'Open/Standard Technology', 'parser': 'N/A', 'notes': 'Company name mentioned in the copyright notice.'}]\n",
            "Ranking:\n",
            " CORRECT\n",
            "\n",
            "CORRECT\n",
            "\n",
            "CORRECT\n",
            "\n",
            "CORRECT\n",
            "\n",
            "CORRECT\n",
            "\n",
            "CORRECT\n",
            "\n",
            "CORRECT\n",
            "Processing section 3 of 8\n",
            "\n",
            "--------------------------------Section 3-----------------------------------\n",
            " ## Table of Contents\n",
            "\n",
            "| Overview |\n",
            "| --- |\n",
            "| Attack Vectors (Infection Routes). |\n",
            "| 1. Spear Phishing |\n",
            "| 2. Watering Hole (Active-X Vulnerability) |\n",
            "| 3. Central Manaqement Solution . |\n",
            "| 4. Supply Chain Attack . |\n",
            "| Attack Cases . |\n",
            "| Malware and Attack Tools . |\n",
            "| 1. Malware – Backdoor …………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………… 11 |\n",
            "| 1.1) Aryan . |\n",
            "| 1.2) Gh0st RAT . |\n",
            "| 1.3) Rifdoor………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………………… 12 |\n",
            "| 1.4) Phandoor |\n",
            "| 1.5) Andaratm |\n",
            "| 2. Attack Tools. |\n",
            "| Similarities in Multiple Attack Cases |\n",
            "| AhnLab's Response. |\n",
            "| Conclusion . |\n",
            "| Reference |\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------results-----------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-10d8d754397a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--------------------------------results-----------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-10d8d754397a>\u001b[0m in \u001b[0;36msend_to_openai\u001b[0;34m(section)\u001b[0m\n\u001b[1;32m     61\u001b[0m     ],\n\u001b[1;32m     62\u001b[0m   )\n\u001b[0;32m---> 63\u001b[0;31m   run = client.beta.threads.runs.create_and_poll(\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mthread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the ID of the Thread generated above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0massistant_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_extractor_ID\u001b[0m \u001b[0;31m# the ID of the Observable Extractor Assistant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/beta/threads/runs/runs.py\u001b[0m in \u001b[0;36mcreate_and_poll\u001b[0;34m(self, assistant_id, include, additional_instructions, additional_messages, instructions, max_completion_tokens, max_prompt_tokens, metadata, model, parallel_tool_calls, reasoning_effort, response_format, temperature, tool_choice, tools, top_p, truncation_strategy, poll_interval_ms, thread_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         )\n\u001b[0;32m--> 851\u001b[0;31m         return self.poll(\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mthread_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/beta/threads/runs/runs.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, run_id, thread_id, extra_headers, extra_query, extra_body, timeout, poll_interval_ms)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                     \u001b[0mpoll_interval_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_ms\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_resource.py\u001b[0m in \u001b[0;36m_sleep\u001b[0;34m(self, seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Define base directories\n",
        "base_path = \"/content/validation\"\n",
        "obs_extractor_ID = \"asst_LFsVfvrlMTkrFFlr3qeNssLV\"\n",
        "\n",
        "\n",
        "def find_md_files(base_path):\n",
        "    \"\"\"Recursively find all .md files in the directory.\"\"\"\n",
        "    md_files = []\n",
        "    for root, _, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".md\"):\n",
        "                md_files.append(os.path.join(root, file))\n",
        "    return md_files\n",
        "\n",
        "def process_md_file(md_file_path):\n",
        "    \"\"\"Read and convert .md file to plain text.\"\"\"\n",
        "    with open(md_file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "def split_into_sections(md_content):\n",
        "    \"\"\"\n",
        "    Split the markdown content into logical sections using markdown headers.\n",
        "\n",
        "    This function uses a regular expression to find headers (lines starting with '#' characters)\n",
        "    and splits the content accordingly. If the file doesn't contain any headers, it returns the entire\n",
        "    content as one section.\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'^(#{1,6}\\s.*)', re.MULTILINE)\n",
        "    matches = list(pattern.finditer(md_content))\n",
        "    sections = []\n",
        "    if not matches:\n",
        "        # No headers found, return the full content as one section.\n",
        "        sections.append(md_content)\n",
        "        # print(sections)\n",
        "        return sections\n",
        "\n",
        "    # Add any content before the first header as its own section if present.\n",
        "    if matches[0].start() > 0:\n",
        "        sections.append(md_content[:matches[0].start()])\n",
        "\n",
        "    # Split content based on header positions.\n",
        "    for i, match in enumerate(matches):\n",
        "        start = match.start()\n",
        "        end = matches[i + 1].start() if i + 1 < len(matches) else len(md_content)\n",
        "        sections.append(md_content[start:end])\n",
        "    print(sections)\n",
        "    return sections\n",
        "\n",
        "def send_to_openai(section):\n",
        "  message_thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "      {\"role\":\"user\", \"content\": section}\n",
        "    ],\n",
        "  )\n",
        "  run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id = message_thread.id, # the ID of the Thread generated above\n",
        "    assistant_id = obs_extractor_ID # the ID of the Observable Extractor Assistant\n",
        "  )\n",
        "  if run.status == 'completed':\n",
        "    messages = client.beta.threads.messages.list(\n",
        "    thread_id= message_thread.id,\n",
        "    )\n",
        "    for message in messages.data:\n",
        "      if message.role == \"assistant\":\n",
        "        messg_id = message.id\n",
        "        result = message.content[0].text.value\n",
        "        print(result)\n",
        "    return result\n",
        "\n",
        "def remove_duplicates(observables_list):\n",
        "    \"\"\"Remove duplicate dictionaries from a list of observables.\"\"\"\n",
        "    unique = []\n",
        "    seen = set()\n",
        "    for item in observables_list:\n",
        "        # Convert dictionary to a JSON string for a consistent, hashable representation.\n",
        "        item_str = json.dumps(item, sort_keys=True)\n",
        "        if item_str not in seen:\n",
        "            seen.add(item_str)\n",
        "            unique.append(item)\n",
        "    return unique\n",
        "\n",
        "\n",
        "# Locate all markdown files in the base directory.\n",
        "md_files = find_md_files(base_path)\n",
        "print(f\"Found {len(md_files)} markdown files.\")\n",
        "\n",
        "results = {}\n",
        "ranking_list = []\n",
        "total_start_time = time.time()\n",
        "\n",
        "# Process each markdown file\n",
        "for md_file in md_files:\n",
        "    print(f\"\\nProcessing file: {md_file}\")\n",
        "    try:\n",
        "        md_content = process_md_file(md_file)\n",
        "        sections = split_into_sections(md_content)\n",
        "        print(f\"File split into {len(sections)} sections.\")\n",
        "\n",
        "        # Initialize an aggregated result for the current file\n",
        "        # aggregated_result = {\n",
        "        #     \"Actionable\": [],\n",
        "        #     \"Described\": [],\n",
        "        #     \"Mentioned\": []\n",
        "\n",
        "        # }\n",
        "\n",
        "        # Process each section separately\n",
        "        for idx, section in enumerate(sections):\n",
        "            # Create a prompt for the current section including an identifier for the section.\n",
        "            # section_prompt = f\"{prompt_template}\\n\\nSection {idx + 1}:\\n{section}\"\n",
        "            section_prompt  = f\"Here is the text snippet: \\n'''\\n{section}\\n'''\"\n",
        "            print(f\"Processing section {idx + 1} of {len(sections)}\")\n",
        "            print(f\"\\n--------------------------------Section {idx+1}-----------------------------------\\n {section}\")\n",
        "            print(f\"\\n--------------------------------results-----------------------------------\\n\")\n",
        "            try:\n",
        "                raw_response = send_to_openai(section_prompt)\n",
        "\n",
        "                if not raw_response.strip():\n",
        "                    raise ValueError(f\"Empty response for section {idx + 1} in file {md_file}\")\n",
        "\n",
        "                # Clean the raw response by removing potential markdown formatting.\n",
        "                cleaned_response = raw_response.strip(\"```\").strip(\"json\").strip()\n",
        "                parsed_response = json.loads(cleaned_response)\n",
        "                #print(parsed_response)\n",
        "                # if \"observables\" in parsed_response:\n",
        "                #     for obs in parsed_response[\"observables\"]:\n",
        "                #         category = obs.get(\"observable_rank\")\n",
        "                #         if category in aggregated_result:\n",
        "                #             aggregated_result[category].append(obs)\n",
        "                print(f'parsed_response type {type(parsed_response)}')\n",
        "                print(f'parsed_response {parsed_response}')\n",
        "                print(f'parsed_response[observables] {parsed_response[\"observables\"]}')\n",
        "\n",
        "                results[os.path.basename(md_file)] = parsed_response\n",
        "                # print(f'results {results}')\n",
        "                if parsed_response[\"observables\"]:          # not empty\n",
        "                  ranking = observable_rank_validator(parsed_response[\"observables\"])\n",
        "                  ranking_list.append(ranking)\n",
        "                  print(\"Ranking:\\n\", ranking)\n",
        "                else:\n",
        "                    print(\"No observables extracted in this section.\")\n",
        "\n",
        "            except Exception as section_error:\n",
        "                print(f\"Error processing section {idx + 1} of {md_file}: {section_error}\")\n",
        "                continue\n",
        "\n",
        "        # Remove duplicates from both observables lists.\n",
        "        # aggregated_result[\"Actionable\"] = remove_duplicates(aggregated_result[\"Actionable\"])\n",
        "        # aggregated_result[\"Described\"] = remove_duplicates(aggregated_result[\"Described\"])\n",
        "        # aggregated_result[\"Mentioned\"] = remove_duplicates(aggregated_result[\"Mentioned\"])\n",
        "\n",
        "        # results[os.path.basename(md_file)] = aggregated_result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {md_file}: {e}\")\n",
        "        results[os.path.basename(md_file)] = {\"error\": str(e)}\n",
        "\n",
        "total_end_time = time.time()\n",
        "total_elapsed = total_end_time - total_start_time\n",
        "print(f\"\\nTotal processing time: {total_elapsed:.2f} seconds.\")\n",
        "\n",
        "# Save the aggregated results to a JSON file.\n",
        "output_file_path = \"/content/results-reports-new-prompt.json\"\n",
        "with open(output_file_path, \"w\") as output_file:\n",
        "    json.dump(results, output_file, indent=4)\n",
        "print(f\"Results saved to {output_file_path}.\")\n",
        "\n",
        "# 4. Save the result to a text file\n",
        "output_path = \"/content/ranking_results.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as out_f:\n",
        "    out_f.write(ranking_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observable-Rank Validator instructions:"
      ],
      "metadata": {
        "id": "mFERcZvmOG1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# # 1. Load file\n",
        "# file_path = \"/content/results-reports-new-prompt.json\"\n",
        "# with open(file_path, 'r', encoding='utf-8') as f:\n",
        "#     observables_data = json.load(f)\n",
        "\n",
        "# # 2. Convert back to a JSON string for the validator\n",
        "# observables_list = json.dumps(observables_data)\n",
        "\n",
        "# # 3. Run the validator\n",
        "# ranking = obsrevable_rank_validator(observables_list)\n",
        "# print(ranking)\n",
        "\n",
        "# # 4. Save the result to a text file\n",
        "# output_path = \"/content/ranking_results.txt\"\n",
        "# with open(output_path, \"w\", encoding=\"utf-8\") as out_f:\n",
        "#     out_f.write(ranking)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnfkCXzUY2gL",
        "outputId": "ea01e466-7706-421f-c5a1-16a1046eccef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NCopy of gh0st3..: INCORRECT — should be \"Described\" because it is only a fragment and ambiguous rather than a complete, unique identifier, note: \"NCopy of gh0st3.\"  \n",
            "%s\\cmd.exe /c echo | %s > %s: INCORRECT — should be \"Described\" because it is a command template with placeholders requiring enrichment rather than a fixed indicator, note: \"%s\\cmd.exe /c echo | %s > %s\"  \n",
            "Putty Link: INCORRECT — should be \"Described\" because the tool name is generic and lacks the uniqueness needed for automated detection, note: \"Putty Link\"  \n",
            "c:\\work>zcon <ip> <port>: INCORRECT — should be \"Described\" because it is a command usage template with placeholders rather than a fixed, matchable string, note: \"c:\\work>zcon <ip> <port>\"  \n",
            "\n",
            "All the remaining observables have the correct observable_rank.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Change Prompt Here (if needed)**\n",
        "\n",
        "so according to the result of the code above, the code snippet (the 8th json in the list in the example), should be actionable. therefore, 1 out of the 17 observables in this list is incorrect and should be corrected.\n",
        "\n",
        "Your job is to try to maximize the ability of the Observable Extractor Assistant by improving its prompt. In the given example the accuracy of the model is high, but in other examples there are alot of mistakes made by the model (rakning code as described instead of actionable and code template as actionable instead of described and such).\n",
        "\n",
        "**you can change the Observable Extractor Assistant instructions using the code below:**"
      ],
      "metadata": {
        "id": "CMzoGMZDLCT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_new_observable_extractor_assistant_instructions = \"\"\"\n",
        "You are a helpful Cybersecurity assistant for identifying observables in Cyber Threat Intelligence text snippets.\n",
        "\n",
        "---\n",
        "### Task\n",
        "\n",
        "1. You will receive a text snippet of a CTI report from a user.\n",
        "2. Read the given snippet (plain text) carefully.\n",
        "3. Extract *every observable* (artifact) mentioned — do *not* omit any.\n",
        "4. For each observable, output a JSON object with the exact fields listed in the *Response format* section.\n",
        "\n",
        "---\n",
        "\n",
        "### Decision Rules\n",
        "\n",
        "| Rank           | Decide “Actionable” **when …**                                                                                                                                      | Typical examples                                                                                                              |\n",
        "| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Actionable** | • The exact string can be matched **as‑is** (or after a trivial transform like Base64 decode).<br>• A detection rule (IDS/YARA/SIEM, PLC logic, etc.) could key on it with low false‑positives.<br>• **Uniqueness is obvious** from its syntax or entropy (i.e. **not** a common filename, generic string, or truncated path). | – Full code snippets / shell commands / SQL queries<br>– Complete URLs, URIs, or file paths<br>– IPs, domains, GUIDs, hashes, registry keys, mutexes, etc. |\n",
        "| **Described**  | • Details are not sufficient to act upon **or** the observable is not directly searchable; ambiguity or missing information.<br>• Additional enrichment (lookup tables, parameter substitution, memory carving, etc.) is required **and** is non‑trivial.<br>• **Generic filenames, ambiguous script names, truncated paths, or common class/object names** belong here rather than Actionable. | – “An HTTP POST to `/api/checkin?id=<random>`” (placeholder)<br>– “A PowerShell script that loads shellcode”<br>– “A DLL named like a system file”<br>– `nc.exe`, `main.exe`, `winrm.vbs` |\n",
        "| **Mentioned**  | • Only generic or conceptual references; **cannot** be turned into a concrete detection even after enrichment.                                                          | – “Uses AES‑128”<br>– “Makes RPC calls”<br>– “Phishing email”                                                                   |\n",
        "\n",
        "---\n",
        "### Definitions\n",
        "\n",
        "1. **Actionable Observable**: meets the **Actionable** rules above.\n",
        "2. **Described Observable**: meets the **Described** rules above (and not **Actionable**).\n",
        "3. **Mentioned Observable**: meets the **Mentioned** rules above.\n",
        "\n",
        "4. *STIX Supported*\n",
        "   • *Full*: the artifact’s type exists in STIX Cyber-Observable Objects.\n",
        "   • *Partial*: supported only via x_ custom properties or the generic artifact object.\n",
        "   • *No*: no direct STIX mapping.\n",
        "\n",
        "5. *Proprietary Artifact*\n",
        "   • Open/Standard Technology\n",
        "   • Proprietary-Documented Technology\n",
        "   • Proprietary-Undocumented Technology\n",
        "\n",
        "---\n",
        "### Handling Large Artifacts\n",
        "\n",
        "- For code snippets, include the *full* code shown in the text, including triple backticks.\n",
        "- If an artifact is encoded (e.g., Base64), include both the *encoded value* and its *decoded value* as separate observables, unless the snippet makes one of them irrelevant.\n",
        "- Treat the most specific string that can stand alone in a detection rule as the observable; you may also mention in its notes the relevant less‑specific substrings if they appear separately in the text.\n",
        "\n",
        "---\n",
        "### Fields to produce for *every* observable\n",
        "\n",
        "| Field                  | What to put                                                                                                   |\n",
        "| ---------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
        "| observable_value     | Exact string (or faithful paraphrase). Escape any internal backticks.                                          |\n",
        "| observable_rank      | Select one — \"Mentioned\", \"Described\", or \"Actionable\" — and assign it *strictly according to the criteria in the *Definitions section for precise ranking.                                                                  |\n",
        "| data_source          | Specify the primary telemetry source (see cheat‑sheet below); do NOT use \"None\" unless the artifact is truly unobservable via telemetry.                                               |\n",
        "| classification       | Short type label (e.g., \"ICS Command\", \"URL\", \"Software/Tool\")                  |\n",
        "| STIX_supported       | \"Full: <STIX_Object_Name>\" | \"Partial\" | \"No\".                                                                     |\n",
        "| proprietary_artifact | \"Open/Standard Technology\" | \"Proprietary-Documented Technology\" | \"Proprietary-Undocumented Technology\".        |\n",
        "| parser               | List well‑known parser(s) for the data format (e.g., \"Zeek\", \"Wireshark\", \"YARA\"); use \"N/A\" or null only when no suitable parser exists.   |\n",
        "| notes                | Any extra comments or context (Markdown allowed), or null if none.                                           |\n",
        "\n",
        "---\n",
        "### Common data_source cheat-sheet\n",
        "\n",
        "Network traffic • Netflow • PCAP • DNS logs • Web proxy logs • Endpoint (EDR) logs • System logs (Windows Event, syslog) • ICS historian • PLC ladder logic • Firewall logs • Cloud API audit logs • Memory dump • None (if not observable via telemetry)\n",
        "\n",
        "---\n",
        "### Response format (return *only* this JSON)\n",
        "\n",
        "json\n",
        "{\n",
        "  \"observables\": [\n",
        "    {\n",
        "      \"observable_value\": \"<VAL>\",\n",
        "      \"observable_rank\": \"Mentioned | Described | Actionable\",\n",
        "      \"data_source\": \"<text>\",\n",
        "      \"classification\": \"<text>\",\n",
        "      \"STIX_supported\": \"Full: <STIX_Object_Name> | Partial | No\",\n",
        "      \"proprietary_artifact\": \"Open/Standard Technology | Proprietary-Documented Technology | Proprietary-Undocumented Technology\",\n",
        "      \"parser\": \"<text>\" | null | \"N/A\",\n",
        "      \"notes\": \"<text>\" | null\n",
        "    }\n",
        "    // … repeat for each unique observable\n",
        "  ]\n",
        "}\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qo8vRdz22nEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs_extractor_ID = \"asst_LFsVfvrlMTkrFFlr3qeNssLV\"\n",
        "our_updated_assistant = client.beta.assistants.update(\n",
        "  obs_extractor_ID, #this is the observable extractor assistant ID\n",
        "  instructions=our_new_observable_extractor_assistant_instructions, # your new instructions\n",
        ")\n",
        "# Notice! this code will update the assistant in OpenAI, so next time you will run the code at the beggining of this notebook, in will call the updated assistant"
      ],
      "metadata": {
        "id": "ILfSxTLDMOhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The original instructions for Observable Extractor Assistant and Observable-Rank Validator:\n",
        "**DO NOT CHANGE THE CODE BELLOW!**"
      ],
      "metadata": {
        "id": "P2H_b6fINUXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observable Extractor Assistant instructions:"
      ],
      "metadata": {
        "id": "_aLGq8qsNtdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs_extractor_instructions = \"\"\"\n",
        "You are a helpful Cybersecurity assistant for identifying observables in Cyber Threat Intelligence text snippets.\n",
        "\n",
        "---\n",
        "### Task\n",
        "\n",
        "1. You will receive a text snippet of a CTI report from a user.\n",
        "2. Read the given snippet (plain text) carefully.\n",
        "3. Extract **every observable** (artifact) mentioned — do **not** omit any.\n",
        "4. For each observable, output a JSON object with the exact fields listed in the **Response format** section.\n",
        "\n",
        "---\n",
        "### Definitions\n",
        "\n",
        "1. **Actionable Observable**\n",
        "   • *Unique & specific* → a deterministic IDS/YARA/SIEM rule could match it with low FP.\n",
        "   • *Immediately operable* **as-is** (code snippet, exact URL, command, file name or path, API function) **or** after simple transform (e.g., Base64 decode, hash lookup, parameter substitution, memory dump).\n",
        "   • A *Searchable* observable, that could plausibly drive automated detection.\n",
        "   If the observable meets these criteria → `observable_rank` = **\"Actionable\"**.\n",
        "\n",
        "2. **Described Observable**\n",
        "   Has notable specifics, but still not unique enough for detection; yet non‑searchable.\n",
        "   If the observable meets these criteria and *not* the Actionable criteria → `observable_rank` = **\"Described\"**.\n",
        "\n",
        "3. **Mentioned Observable**\n",
        "   A non‑searchable observable that meets neither the Actionable nor Described criteria.\n",
        "   → `observable_rank` = **\"Mentioned\"**.\n",
        "\n",
        "4. **STIX Supported**\n",
        "   • **Full**: the artifact’s type exists in STIX Cyber-Observable Objects.\n",
        "   • **Partial**: supported only via `x_` custom properties or the generic `artifact` object.\n",
        "   • **No**: no direct STIX mapping.\n",
        "\n",
        "5. **Proprietary Artifact**\n",
        "   • Open/Standard Technology\n",
        "   • Proprietary-Documented Technology\n",
        "   • Proprietary-Undocumented Technology\n",
        "\n",
        "---\n",
        "### Handling Large Artifacts\n",
        "\n",
        "- For code snippets, include the **full** code shown in the text, including triple backticks.\n",
        "- If an artifact is encoded (e.g., Base64), include both the **encoded value** and its **decoded value** as separate observables, unless the snippet makes one of them irrelevant.\n",
        "- Treat the most specific string that can stand alone in a detection rule as the observable; you may also mention in its notes the relevant less‑specific substrings if they appear separately in the text.\n",
        "\n",
        "---\n",
        "### Fields to produce for **every** observable\n",
        "\n",
        "| Field                  | What to put                                                                                                   |\n",
        "| ---------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
        "| `observable_value`     | Exact string (or faithful paraphrase). Escape any internal backticks.                                          |\n",
        "| `observable_rank`      | \"Mentioned\" | \"Described\" | \"Actionable\" based on the definitions above.                                                                  |\n",
        "| `data_source`          | Where it can be observed or collected (see cheat-sheet below).                                                |\n",
        "| `classification`       | Short type label (e.g., \"ICS Command\", \"URL\", \"Software/Tool\")                  |\n",
        "| `STIX_supported`       | \"Full: <STIX_Object_Name>\" | \"Partial\" | \"No\".                                                                     |\n",
        "| `proprietary_artifact` | \"Open/Standard Technology\" | \"Proprietary-Documented Technology\" | \"Proprietary-Undocumented Technology\".        |\n",
        "| `parser`               | Known open-source/commercial parser name(s) for the data format, else `null` or \"N/A\" if not applicable.   |\n",
        "| `notes`                | Any extra comments or context (Markdown allowed), or `null` if none.                                           |\n",
        "\n",
        "---\n",
        "### Common `data_source` cheat-sheet\n",
        "\n",
        "Network traffic • Netflow • PCAP • DNS logs • Web proxy logs • Endpoint (EDR) logs • System logs (Windows Event, syslog) • ICS historian • PLC ladder logic • Firewall logs • Cloud API audit logs • Memory dump • None (if not observable via telemetry)\n",
        "\n",
        "---\n",
        "### Response format (return **only** this JSON)\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"observables\": [\n",
        "    {\n",
        "      \"observable_value\": \"<VAL>\",\n",
        "      \"observable_rank\": \"Mentioned | Described | Actionable\",\n",
        "      \"data_source\": \"<text>\",\n",
        "      \"classification\": \"<text>\",\n",
        "      \"STIX_supported\": \"Full: <STIX_Object_Name> | Partial | No\",\n",
        "      \"proprietary_artifact\": \"Open/Standard Technology | Proprietary-Documented Technology | Proprietary-Undocumented Technology\",\n",
        "      \"parser\": \"<text>\" | null | \"N/A\",\n",
        "      \"notes\": \"<text>\" | null\n",
        "    }\n",
        "    // … repeat for each unique observable\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NVHZ1gaiN4DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}